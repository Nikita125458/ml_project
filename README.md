# Titanic — бинарная классификация выживаемости

## Описание задачи и датасета

Проект решает задачу бинарной классификации на датасете **Titanic**: по информации о пассажире нужно предсказать, выжил он в катастрофе или нет (`Survived`: 1 — выжил, 0 — погиб). Данные описывают пассажиров лайнера «Титаник» с признаками пола, возраста, класса билета, стоимости билета, каюты и порта посадки.

Основные поля датасета:

- `PassengerId` — уникальный идентификатор пассажира (служебный).  
- `Survived` — целевая переменная (1 — выжил, 0 — погиб).  
- `Pclass` — класс билета (1 — высший, 2 — средний, 3 — низший).  
- `Name` — полное имя пассажира.  
- `Sex` — пол (`male` / `female`).  
- `Age` — возраст (часть значений отсутствует).  
- `SibSp` — число братьев/сестер и супругов на борту.  
- `Parch` — число родителей и детей на борту.  
- `Ticket` — номер билета.  
- `Fare` — стоимость билета.  
- `Cabin` — номер каюты (много пропусков).  
- `Embarked` — порт посадки (`S`, `C`, `Q`).  

## Используемые технологии

- Python, **pandas** — загрузка и предобработка табличных данных.  
- **scikit‑learn** — `train_test_split`, метрика `accuracy_score`, кодирование категориальных признаков через `LabelEncoder`.  
- **python‑dotenv** — чтение конфигурации обучения (пути к данным и гиперпараметры) из файла `envs/.params.env`.  
- **PyTorch** — реализация и обучение полносвязной нейронной сети для бинарной классификации (функция потерь `BCEWithLogitsLoss`, оптимизатор Adam).  

## Конфигурация через .env

Параметры обучения и пути к данным задаются во внешнем файле `envs/.params.env` и считываются в коде с помощью `load_dotenv`:

- `TRAIN_DATA_URL` — URL обучающего датасета (`train.csv`).  
- `TEST_DATA_URL` — URL тестового датасета (`test.csv`).  
- `TEST_SIZE` — доля данных для валидационной выборки при разбиении `train_test_split`.  
- `EPOCHS` — число эпох обучения модели.  
- `MODEL_PARAMETER_1` — размер скрытого слоя нейросети.  

## Предобработка данных

1. Загружаются `train_df` и `test_df` по URL из файла `.env`; из `train_df` формируются признаки `X_train` (без `Survived`, `Ticket`, `Name`), а из `test_df` — `X_test` (без `Ticket`, `Name`).  
2. Для числовых признаков (`Age`, `Fare`, `SibSp`, `Parch`, `Pclass`) пропуски заполняются медианой по соответствующему столбцу, для категориальных (`Embarked`, `Sex`, `Cabin`) — модой.  
3. Признак `Sex` преобразуется в бинарный формат: значение `female` кодируется как 1, остальные как 0.  
4. Из признака `Cabin` выделяется палуба (первая буква номера каюты), после чего признаки `Embarked` и палуба каюты кодируются целыми числами с помощью `LabelEncoder`, обученного на обучающем наборе и затем применённого к обучающему и тестовому данным.  
5. Целевая переменная `y_train` приводится к целочисленному типу; далее `X_train` и `y_train` разбиваются на обучающую и валидационную части с помощью `train_test_split` с долей `TEST_SIZE`.  

## Первая модель и обучение

1. Матрицы признаков (`X_train`, `X_val`, `X_test`) и векторы целевой переменной (`y_train`, `y_val`) преобразуются в тензоры PyTorch типа `float32`.  
2. Определяется модель `SimpleNet` — полносвязная нейронная сеть с одним скрытым слоем: линейный слой `Linear(input_dim, 16)`, нелинейность ReLU и выходной слой `Linear(16, 1)` с последующей функцией потерь `BCEWithLogitsLoss` для бинарной классификации.  
3. Модель обучается на обучающей выборке `X_train_t`, `y_train_t` с оптимизатором Adam и фиксированным числом эпох `EPOCHS`; каждые 10 эпох вычисляется accuracy на валидационной выборке `X_val_t`, `y_val_t`.  
4. После обучения модель переводится в режим оценки и используется для получения прогнозов на тестовом наборе `X_test_t`; предсказанные метки `Survived` выводятся и могут быть сохранены для отправки на соревнование или анализа.  

## Вторая модель и обучение

В качестве второй модели используется двухслойная полносвязная нейронная сеть (MLP), которая принимает те же предобработанные признаки, что и первая модель, но содержит два скрытых слоя размерности `MODEL_PARAMETER_1` с функцией активации ReLU между ними и выходным нейроном размерности 1 для предсказания логитов вероятности выживания с последующей функцией потерь `BCEWithLogitsLoss`. [web:221]  

Обучение второй модели проводится на тех же тензорах `X_train_t` и `y_train_t` с оптимизатором Adam и числом эпох `EPOCHS`, при этом каждые 10 эпох вычисляется значение функции потерь и метрика accuracy на валидационной выборке `X_val_t`, `y_val_t`, что позволяет сравнить качество двух моделей при одинаковых условиях обучения. [web:221]  

После завершения обучения двухслойная MLP переводится в режим инференса и используется для вычисления логитов на тестовом наборе `X_test_t`, которые превращаются в вероятности через сигмоиду и бинаризуются по порогу 0.5, формируя итоговые предсказания признака `Survived` для каждого пассажира, пригодные для анализа и сравнения с результатами первой модели. [web:221]  
